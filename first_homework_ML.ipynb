{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ef32fc",
   "metadata": {},
   "source": [
    "# SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d57467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Sklearn modules & classes\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd356041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set\n",
    "bc = datasets.load_breast_cancer(as_frame=True)\n",
    "X = bc.data\n",
    "y = bc.target\n",
    " \n",
    "# Create training and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf47b34",
   "metadata": {},
   "source": [
    "The breast cancer dataset is a classic and very easy binary classification dataset.\n",
    "\n",
    "Classes:2\n",
    "\n",
    "Samples per class:212(M),357(B)\n",
    "\n",
    "Samples total:569\n",
    "\n",
    "Dimensionality:30\n",
    "\n",
    "Features:real, positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4335fa",
   "metadata": {},
   "source": [
    "lets see some discreption of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc3a02f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(bc.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c44c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8df16b",
   "metadata": {},
   "source": [
    "kernel parameters selects the type of hyperplane used to separate the data. \n",
    "Using ‘linear’ will use a linear hyperplane (a line in the case of 2D data). \n",
    "‘rbf’ and ‘poly’ uses a non linear hyper-plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd27161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " kernel: linear\n",
      "svc model intercept: [0.31885692]\n",
      "R-squared score (training): 0.990\n",
      "R-squared score (test): 0.953\n",
      " kernel: rbf\n",
      "svc model intercept: [-0.25627728]\n",
      "R-squared score (training): 0.990\n",
      "R-squared score (test): 0.977\n",
      " kernel: poly\n",
      "svc model intercept: [0.6672142]\n",
      "R-squared score (training): 0.902\n",
      "R-squared score (test): 0.901\n"
     ]
    }
   ],
   "source": [
    "kernels = [\"linear\", \"rbf\", \"poly\"]\n",
    "for kernel in kernels:\n",
    "    svc= SVC(kernel=kernel).fit(X_train_std, y_train)\n",
    "    print(\" kernel: \"+ str(kernel))\n",
    "    print('svc model intercept: {}'\n",
    "     .format(svc.intercept_))\n",
    "#     print('svc model coeff:\\n{}'\n",
    "#      .format(svc.coef_))\n",
    "    print('R-squared score (training): {:.3f}'\n",
    "     .format(svc.score(X_train_std, y_train)))\n",
    "    print('R-squared score (test): {:.3f}'\n",
    "     .format(svc.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729d6575",
   "metadata": {},
   "source": [
    "gamma is a parameter for non linear hyperplanes.\n",
    "The higher the gamma value it tries to exactly fit the training data set\n",
    "\n",
    "overfit عند ارتفاع قيمتها نلاحظ حصول"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eedf8703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gammas' value : auto\n",
      "svc model intercept: [-0.25627728]\n",
      "R-squared score (training): 0.990\n",
      "R-squared score (test): 0.977\n",
      " gammas' value : 0.1\n",
      "svc model intercept: [-0.20591511]\n",
      "R-squared score (training): 0.995\n",
      "R-squared score (test): 0.942\n",
      " gammas' value : 1\n",
      "svc model intercept: [0.32223834]\n",
      "R-squared score (training): 1.000\n",
      "R-squared score (test): 0.626\n",
      " gammas' value : 10\n",
      "svc model intercept: [0.4079998]\n",
      "R-squared score (training): 1.000\n",
      "R-squared score (test): 0.626\n",
      " gammas' value : 100\n",
      "svc model intercept: [0.408]\n",
      "R-squared score (training): 1.000\n",
      "R-squared score (test): 0.626\n"
     ]
    }
   ],
   "source": [
    "gammas = [\"auto\",0.1, 1, 10, 100]\n",
    "for gamma in gammas:\n",
    "    svc = SVC(kernel=\"rbf\", gamma=gamma).fit(X_train_std, y_train)\n",
    "    print(\" gammas' value : \"+ str(gamma))\n",
    "    print('svc model intercept: {}'\n",
    "     .format(svc.intercept_))\n",
    "#     print('svc model coeff:\\n{}'\n",
    "#      .format(svc.coef_))\n",
    "    print('R-squared score (training): {:.3f}'\n",
    "     .format(svc.score(X_train_std, y_train)))\n",
    "    print('R-squared score (test): {:.3f}'\n",
    "     .format(svc.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb9162c",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "C is the penalty parameter of the error term.\n",
    "It controls the trade off between smooth decision boundary and classifying the training points correctly.\n",
    "\n",
    "\n",
    "regularization يمثل هذا المتغير قيمة ال"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf015b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =0.1\n",
      "svc model intercept: [-0.22787928]\n",
      "R-squared score (training): 0.950\n",
      "R-squared score (test): 0.947\n",
      "C =1\n",
      "svc model intercept: [-0.25627728]\n",
      "R-squared score (training): 0.990\n",
      "R-squared score (test): 0.977\n",
      "C =10\n",
      "svc model intercept: [-0.30622816]\n",
      "R-squared score (training): 0.995\n",
      "R-squared score (test): 0.971\n",
      "C =100\n",
      "svc model intercept: [-0.35306207]\n",
      "R-squared score (training): 1.000\n",
      "R-squared score (test): 0.971\n",
      "C =1000\n",
      "svc model intercept: [-0.35306207]\n",
      "R-squared score (training): 1.000\n",
      "R-squared score (test): 0.971\n"
     ]
    }
   ],
   "source": [
    "cs = [0.1, 1, 10, 100, 1000]\n",
    "for c in cs:\n",
    "    svc = SVC(kernel=\"rbf\",gamma=\"auto\", C=c).fit(X_train_std, y_train)\n",
    "    print(\"C =\" + str(c))\n",
    "    print('svc model intercept: {}'\n",
    "     .format(svc.intercept_))\n",
    "    print('R-squared score (training): {:.3f}'\n",
    "     .format(svc.score(X_train_std, y_train)))\n",
    "    print('R-squared score (test): {:.3f}'\n",
    "     .format(svc.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04acd0f",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "عند ارتفاع قيمته نلاحظ حصول overfit \n",
    "وأفضل قيمة له هي 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12609d",
   "metadata": {},
   "source": [
    "best parameter (kernel = rbf,C = 1, gamma = auto)\n",
    "\n",
    "    -svc model intercept: [-0.25627728]\n",
    "    -R-squared score (training): 0.990\n",
    "    -R-squared score (test): 0.977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ba154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a74559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0b5c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "classifier_svm = SVC (kernel = 'rbf', random_state = 0)\n",
    "classifier_svm.fit (X_train, y_train)\n",
    "Y_pred_svm = classifier_svm.predict (X_test)\n",
    "acc_svm = accuracy_score (y_test, Y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dab0ae8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9239766081871345"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e8cf252",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15108\\1224784631.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                            \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                            n_jobs = -1)\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mbest_accuracy_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mbest_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    849\u001b[0m                     )\n\u001b[0;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[1;32m--> 851\u001b[1;33m                         \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m                     )\n\u001b[0;32m    853\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = [{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'kernel': ['linear', 'rbf'],\n",
    "                'gamma': ['auto',0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier_svm,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy_svm = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(best_accuracy_svm)\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96403cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78490245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16d0260c",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf4840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set\n",
    "bc = datasets.load_breast_cancer(as_frame=True)\n",
    "X = bc.data\n",
    "y = bc.target\n",
    " \n",
    "# Create training and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c7c120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "classifier_log = LogisticRegression ()\n",
    "classifier_log.fit (X_train, y_train)\n",
    "Y_pred_log = classifier_log.predict (X_test)\n",
    "acc_log = accuracy_score (y_test, Y_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45616fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935672514619883"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8b54736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "210 fits failed out of a total of 700.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.91455128        nan 0.89955128 0.94730769\n",
      " 0.93474359 0.92467949 0.90705128 0.89955128        nan        nan\n",
      " 0.92211538        nan 0.89955128 0.94230769 0.93217949 0.93217949\n",
      " 0.90705128 0.89955128        nan        nan 0.92724359        nan\n",
      " 0.89955128 0.94730769 0.93980769 0.93980769 0.90705128 0.89955128\n",
      "        nan        nan 0.94987179        nan 0.89955128 0.95487179\n",
      " 0.94224359 0.94980769 0.90705128 0.89955128        nan        nan\n",
      " 0.95730769        nan 0.89955128 0.95230769 0.95230769 0.95480769\n",
      " 0.90705128 0.89955128        nan        nan 0.96737179        nan\n",
      " 0.89955128 0.95987179 0.94980769 0.95737179 0.90705128 0.89955128\n",
      "        nan        nan 0.95487179        nan 0.89955128 0.96237179\n",
      " 0.95230769 0.95987179 0.90705128 0.89955128]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9673717948717948\n",
      "{'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# solver --> optimization\n",
    "# C --> regularization strength >> Smaller values specify stronger regularization\n",
    "# penalty --> regularization\n",
    "parameters = [{'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}]\n",
    "grid_search = GridSearchCV(estimator = classifier_log,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy_log = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(best_accuracy_log)\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d770b031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaea067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455a03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caf6febf",
   "metadata": {},
   "source": [
    "## knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca76106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set\n",
    "bc = datasets.load_breast_cancer(as_frame=True)\n",
    "X = bc.data\n",
    "y = bc.target\n",
    " \n",
    "# Create training and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bb18e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier_knn = KNeighborsClassifier ()\n",
    "classifier_knn.fit (X_train, y_train)\n",
    "Y_pred_knn = classifier_knn.predict (X_test)\n",
    "acc_knn = accuracy_score (y_test, Y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17e8c7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abfe234e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9498076923076922\n",
      "{'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# n_neighbors --> represents the number of neighbors to use for kneighbors queries\n",
    "# weights --> how weight should be distributed between neighbor values. uniform: weights to be distributed equally\n",
    "# p --> for the Minkowski metric. p = 1 -> manhattan_distance (l1), euclidean_distance (l2) for p = 2.\n",
    "parameters = [{'n_neighbors': [3,5,7,10,13,15], 'weights': ['uniform', 'distance'],\n",
    "                'p': [1,2]}]\n",
    "grid_search = GridSearchCV(estimator = classifier_knn,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy_knn = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(best_accuracy_knn)\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fc914c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21120da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8a042c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a2a962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bafcb5d0",
   "metadata": {},
   "source": [
    "## naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6057fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier_nb = GaussianNB ()\n",
    "classifier_nb.fit (X_train, y_train)\n",
    "Y_pred_nb = classifier_nb.predict (X_test)\n",
    "cm_nb = confusion_matrix (y_test, Y_pred_nb)\n",
    "acc_nb = accuracy_score (y_test, Y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dd98e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935672514619883"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e83a00",
   "metadata": {},
   "source": [
    "there are no parameters to tune "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59484ab7",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da297ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier_dtc = DecisionTreeClassifier (criterion = 'entropy', random_state = 0)\n",
    "classifier_dtc.fit (X_train, y_train)\n",
    "Y_pred_dtc = classifier_dtc.predict (X_test)\n",
    "acc_dtc = accuracy_score (y_test, Y_pred_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5171a670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52636937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9475\n",
      "{'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 15, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# criterion --> measure the quality of a split\n",
    "#min_samples_split --> minimum number of samples required to split an internal node:\n",
    "#max_depth -> deep of the tree\n",
    "\n",
    "parameters = [{'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150], \n",
    "                'max_leaf_nodes': [2,4,6,10,15,30,40,50,100], 'min_samples_split': [2, 3, 4]}]\n",
    "grid_search = GridSearchCV(estimator = classifier_dtc,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy_dtc = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(best_accuracy_dtc)\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ad943a",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50b377e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_rfc = RandomForestClassifier (n_estimators = 100, criterion = 'entropy', random_state = 1)\n",
    "classifier_rfc.fit (X_train, y_train)\n",
    "Y_pred_rfc = classifier_rfc.predict (X_test)\n",
    "acc_rfc = accuracy_score (y_test, Y_pred_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fea8e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590643274853801"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "732551f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "240 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 467, in fit\n",
      "    for i, t in enumerate(trees)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 264, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 264, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 942, in fit\n",
      "    X_idx_sorted=X_idx_sorted,\n",
      "  File \"C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 305, in fit\n",
      "    if max_depth <= 0:\n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\HP\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.9624359  0.9649359  0.9674359  0.96237179 0.9649359  0.9674359\n",
      " 0.9624359  0.9649359  0.9649359  0.96237179 0.9649359  0.9674359\n",
      " 0.9624359  0.9649359  0.9674359  0.96237179 0.9649359  0.9674359\n",
      " 0.9624359  0.9649359  0.9649359  0.96237179 0.9649359  0.9674359\n",
      " 0.9624359  0.9649359  0.9674359  0.96237179 0.9649359  0.9674359\n",
      " 0.9624359  0.9649359  0.9649359  0.96237179 0.9649359  0.9674359\n",
      " 0.9624359  0.9649359  0.9674359  0.96237179 0.9649359  0.9674359\n",
      " 0.9624359  0.9649359  0.9649359  0.96237179 0.9649359  0.9674359\n",
      " 0.9624359  0.9649359  0.9674359  0.96237179 0.9649359  0.9674359\n",
      " 0.9624359  0.9649359  0.9649359  0.96237179 0.9649359  0.9674359\n",
      " 0.9624359  0.9649359  0.9674359  0.96237179 0.9649359  0.9674359\n",
      " 0.9624359  0.9649359  0.9649359  0.96237179 0.9649359  0.9674359\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9674358974358974\n",
      "{'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "parameters = [{'n_estimators': [100,200,300],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [10,25,50,'none'],\n",
    "               'min_samples_leaf': [1, 2], \n",
    "               'min_samples_split': [2, 5]}]\n",
    "grid_search = GridSearchCV(estimator = classifier_rfc,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy_rfc = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(best_accuracy_rfc)\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48952f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
